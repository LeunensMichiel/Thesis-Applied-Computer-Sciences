%%=============================================================================
%% Conclusie
%%=============================================================================

\chapter{Conclusie}
\label{ch:conclusie}

%% TODO: Trek een duidelijke conclusie, in de vorm van een antwoord op de
%% onderzoeksvra(a)g(en). Wat was jouw bijdrage aan het onderzoeksdomein en
%% hoe biedt dit meerwaarde aan het vakgebied/doelgroep? Reflecteer kritisch
%% over het resultaat. Had je deze uitkomst verwacht? Zijn er zaken die nog
%% niet duidelijk zijn? Heeft het onderzoek geleid tot nieuwe vragen die
%% uitnodigen tot verder onderzoek?

Nu de middleware gepubliceerd is en binnengetrokken op de servers van Kayzr, kan er worden bekeken of hij voldoet aan de vereisten, of er voordelen en al dan niet extra nice-to-haves uit te halen zijn, en of er verbeteringen kunnen plaatsvinden. Dit hoofdstuk is gewijd aan het toetsen van de geschreven software aan de praktijk.

\section{Meting aan de vereisten}
\label{sec:reqs}

Vooraleer er een definitieve conclusie wordt gemaakt, moet er eerst gekeken worden of de middleware natuurlijk aan alle opgesomde vereisten voldoet, zoals beschreven in hoofdstuk \ref{sec:requirements}. We starten met de eerste vereiste:

\subsection{Toetsing}
\label{sec:testing}

\begin{quote}
	\textit{"Hoeveel keer wordt een bepaalde API call uitgevoerd in een specifieke tijdspanne? Kan Kayzr hierdoor bekijken welke API calls tijdens drukke uren te veel worden opgeroepen en de applicatie vertragen?"}
\end{quote}

Dankzij de \textit{Number of Requests-}tabel, kan dit nu volledig bekeken worden. Men kan kijken hoeveel API calls doorkomen per 10 seconden, of per uur, of per dag... maar men kan ze ook nog eens groeperen per soort response. Hoeveel 4xx of 5xx calls (calls die foutmeldingen geven) komen door? Ook via de \textit{basics-}tabel kan er veel extra informatie opgevraagd worden. Zo kan men bijvoorbeeld kijken of er tussen 2 pm en 4 pm enkele requests voorkwamen die een grotere uitvoertijd dan twintig milliseconden hadden en dus een zware last zouden vormen voor de servers.

\begin{quote}
	\textit{In Google Cloud Stack Driver kan men mooi de errors terugvinden die voorkwamen op de backend server. Maar hier staat nergens de URL van de opgeroepen API call bij. Waar is deze fout beginnen optreden? Kan men die URL verkrijgen opdat men niet moet zoeken naar een naald in een hooiberg?}
\end{quote}

\begin{quote}
	\textit{Kunnen deze fouten ergens opgeslagen worden opdat men later deze fouten makkelijker kan terugvinden?}
\end{quote}


Dit is volledig opgelost. Door de \textit{errors-}tabel te observeren kan men namelijk
\begin{enumerate}
	\item kijken op welke URL en pad de fout zich voordeed
	\item lezen welke foutmeldingen er werden geregistreerd, samen met de error stack van de desbetreffende fout.
	\item Ook nuttige parameters aflezen zodat men context kan plaatsen bij de fout. Parameters zoals de request body, authentication token, queries enzovoort.
\end{enumerate}

Fouten kunnen ook opgezocht worden met behulp van een zoekfunctionaliteit, en worden ook geordend volgend error stack en vervolgens volgens error message. Zo worden duplicaten weggefilterd en wordt er een zeer praktisch en gebruikersvriendelijk overzicht weergegeven.

\begin{quote}
	\textit{Kan men de (gemiddelde) tijd monitoren tussen het versturen van een bepaalde API call en een verkregen antwoord?}
\end{quote}

De gemiddelde tijd wordt gemonitord en kan in de meeste tabellen teruggevonden worden. Ook is het mogelijk om de gemiddelde tijd van database-calls te monitoren. Hierover wordt later nog meer uitleg gegeven.

\begin{quote}
	\textit{Monitoren van deze Node.js processen hun taxatie op de server waar ze op draaien (CPU, RAM, netwerk,…)}
\end{quote}

Geheugenverbruik en processorverbruik worden per server weergeven in de desbetreffende \textit{performantie-}tabellen.


\begin{quote}
	\textit{Middleware als Morgan toont veel te weinig, Google Cloud Stack Driver toont veel maar geeft geen context mee. De eerder opgesomde betalende monitoringsoftwares bevatten te veel functies die Kayzr niet meteen zou gebruiken, maar wel handig \textit{zouden kunnen} zijn. Dit verantwoordt echter hun grote kostprijs niet, en Kayzr wenst dus dat budget er niet aan te spenderen. Bestaat er geen goede middenweg?}
\end{quote}

Deze tool heeft al bewezen dat hij zeer veel zaken aankan, en schaalbaar is om er meerdere uitbreidingen aan toe te voegen. In de eerste release kan deze hij al meer dan Morgan, neemt alle delen die Kayzr handig vindt van over Google Cloud Stack Driver en zet ze om in een eigen Grafana werkomgeving, een werkomgeving die geïmporteerd kan worden in een eigen configuratie waardoor het niet verplicht is om eigen grafieken beginnend van niets op te stellen.

De kost van een Grafana-server voor Kayzr bedraagt ongeveer vijftien euro per maand. Dit is puur voor hosting van een server, en is helemaal geen grote kost. De meeste functionaliteiten van de betalende oplossingen (waarvan prijs veel hoger lag, zoals beschreven in \ref{sec:tools}), waren overbodig. Functionaliteiten zoals error stack tracing, konden makkelijk zelf geïmplementeerd worden. En aangezien de middleware open-source en in actieve ontwikkeling is, spreekt het ook voor zich dat in de toekomst meerdere functionaliteiten gaan kunnen toegevoegd worden. Vijftien euro per maand om één server te laten draaien die informatie van verschillende servers kan verzamelen, tegenover gemiddeld zeventig euro per maand \textit{per server} voor een veel te uitgebreide tool, kan natuurlijk als een groot pluspunt van express-influx-multilogger worden beschouwd.

\begin{quote}
	\textit{Afhankelijk zijn van betalende services betekent ook dat de data van Kayzr terecht komen bij (dure) third party oplossingen. Zijn die data veilig? Volgen ze de GDPR regels? Ze houden liever hun data in eigen beheer.}
\end{quote}

De data van Kayzr worden veilig opgeslagen op hun eigen servers. Niemand buiten Kayzr kan aan die data, wat een groot pluspunt is in een tijd waarin privacywetgeving nog nooit zo belangrijk werd geacht.

\begin{quote}
	\textit{Men wil niet enkel realtime zaken kunnen bekijken, maar ook data opslaan zodat die op een later moment nog eens bekeken kunnen worden.}
\end{quote}

InfluxDB is overal beschikbaar op de servers van Kayzr. Indien de data nog ergens anders moeten gebruikt worden, kan dat zonder enige moeite.

\subsection{Nice-to-have}
\label{sec:nicetohave}

Verder werden er nog enkele optionele functionaliteiten toegevoegd. Dezen worden hieronder opgesomd. Meerdere extraatjes kunnen mogelijks later nog worden toegevoegd.
\pagebreak
\subsubsection{Geolocatie}
\label{sec:geolocation}

Kayzr kan nu op een interactieve wereldkaart bekijken waar het merendeel van de verzoeken vandaan komt. Er werd geopteerd om de locatie te traceren via een binnenkomend ip-adres. Dit is allesbehalve de meest precieze methode, maar ze voldoet om het land van herkomst te detecteren. Ook wordt er op deze manier geen privacy geschonden van de eindgebruiker. Eindgebruikers die zich via een vpn-service zouden verbinden kunnen worden verwaarloosd, aangezien deze meetpunten relatief weinig voorkomen.

Deze nieuwe functionaliteit is handig om te kijken of een toernooi populairder is in België of Nederland, en of Kayzr misschien kan uitbreiden naar het buitenland.

\subsubsection{Databank metrieken}
\label{sec:databaseMetrics}

Sinds versie 1.0.9 is het ook mogelijk om op een willekeurige plek een multilogger-functie op te roepen in de eigen backend. Deze functie biedt de mogelijkheid om een naam, timings en extra parameters toe te voegen. Zo kan men bijvoorbeeld een specifieke call naar een databank timen (bijvoorbeeld: hoe lang duurt het om een nieuwe gebruiker weg te schrijven naar MySQL). De naam van deze databank en de gemeten tijd stuurt men dan mee door, samen met extra optionele parameters. Al deze informatie wordt dan weggewerkt naar InfluxDB en kan dan ook in Grafana worden bekeken. 

\begin{lstlisting}[style=ES6, caption={Extra informatie wordt doorgestuurd naar InfluxDB},label=code:addToObject]
const addToObject = ({ name, timing, ...custom } = {}) => {
	let databaseMetrics = {
		name,
		timing
	};
	_.flatMap(custom, param => {
		return _.map(param, (value, key) => {
			return (databaseMetrics[key] = value);
		});
	});
	object.databaseMetrics.push(databaseMetrics);
};
\end{lstlisting}
\begin{minipage}{\linewidth}
\begin{lstlisting}[style=ES6, caption={Deze functie kan overal in de API worden opgeroepen},label=code:plugin]
router.get("/", function(req, res, next) {
	multilogger.insertDatabaseCallSpeed({
		name: "Testje",
		timing: 5.203,
		custom: {
			optionalInfo: "1",
			2: "3",
			foo: "fighters",
			objectAverageExample: object.example
		}
	});
	res.send("Got a GET request");
	next();
});
\end{lstlisting}
\end{minipage}

\section{Hoe ziet Kayzr de toekomst?}
\label{sec:future}

Uit de voorgaande opsomming blijkt dat de onderzoeksdoelstelling werd bereikt, en de onderzoeksvraag werd beantwoord. Kayzr zelf liet weten dat ze zeer tevreden zijn met de nieuwe beschikbare tool en willen deze meteen op al hun servers laten draaien. Zo kan er al meteen informatieve data worden opgehaald van de gloednieuwe CSGO (Counter Strike: Global Offensive) servers, zodat productiesnelheid omhoog kan.

Ook gaan ze dankzij de extra database-metriekfunctionaliteit de database processen stresstesten van hun zelfgeschreven data-abstractielaag, genaamd \textit{gnewmine} en kijken waar deze laatste geoptimaliseerd zal kunnen worden.

\section{Uitbreiding en verder onderzoek}
\label{sec:expansin}

Dit onderzoek heeft aangetoond dat een debugoplossing in Node.js en Express niet duur hoeft te zijn. Met slechts 1 enkele extra server kan er een middleware geschreven worden die al het werk voor je doet. 

Het enige nadeel is dat er een bijkomende leercurve achter zit. Niet enkel voor het maken van de middleware, maar ook voor het instellen van InfluxDB en het opstellen van grafieken in Grafana. Dit onderzoek stelt echter ook alle middelen open naar andere ontwikkelaars, zodat er veel werk bespaard kan worden. Zo kan de middleware gedownload worden via npm, en kan eenmaal de server is opgesteld, het meegegeven configuratiebestand in de README.md geïmporteerd worden in Grafana waardoor het dashboard automatisch wordt ingesteld. Het hele pakket is open-source, dus de middleware staat open voor extra uitbreidingen.

Dit onderzoek kan vervolledigd worden door requirements van andere bedrijven, die in dezelfde situatie zitten, toe te voegen aan de software. Ook kan het verder worden uitgebreid door sommige elementen te optimaliseren, zoals het wegschrijven naar InfluxDB, meer met asynchrone processen te werken en betere ontwerppatronen te volgen. De software zou meer testen moeten bevatten, en fouten zouden nog sneller moeten worden opgevangen om crashmogelijkheden te beperken. Grafieken van Grafana staan open voor uitbreiding zodat uit dezelfde data nog meer informatie kan gehaald worden. Ondersteuning voor meerdere database-management systemen is zeker en vast een must om deze middleware oplossing bij meer ontwikkelaars populair te maken.
